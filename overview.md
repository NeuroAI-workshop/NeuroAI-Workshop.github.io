---
layout: page
title: "Overview"
permalink: /overview/
---

<!-- # Overview -->

Welcome to the NeurIPS 2025 NeuroAI Workshop! Building on the success of our inaugural event, this year’s workshop continues to bring together researchers and practitioners from neuroscience and artificial intelligence to deepen cross-disciplinary collaboration and insight.

We are in a period of rapid progress in artificial intelligence, marked by the rise of large-scale models in language, vision, and multimodal learning (e.g., GPT-4o, Gemini, Sora). As these systems scale, there is growing interest in understanding and emulating the principles of biological intelligence. The field of NeuroAI --at the intersections of artificial and natural intelligence -- aims to bridge neuroscience and AI, leveraging insights from brain function to develop more robust, efficient, and interpretable models.

This burgeoning NeuroAI field is anchored by several key research areas including but not limited to:


- **Neuro-inspired Computations:** This research focuses on developing hardware and algorithms inspired by the biological neuronal structure and function, such as spiking neural networks and Hebbian plasticity. Incorporating neuro-inspired mechanisms such as continual learning principles allows these systems to adapt and improve over time without requiring retraining from scratch, further enhancing their robustness and applicability in dynamic scenarios. For instance, recent advancements in neuromorphic computing, particularly the development of Intel’s Loihi chip, demonstrate the potential of spiking neural networks to improve the efficiency and capabilities of artificial systems. The Loihi chip mimics the brain’s neuronal architectures and synaptic plasticity mechanisms, enabling more efficient processing and learning in real-time environments.

- **Explainable AI in Neuroscience:** This research explores the integration of AI models with neuroscientific principles to enhance interpretability and explainability. For instance, the use of neural network architectures inspired by the human brain’s hierarchical processing can improve the interpretability of complex models by aligning them with known neural mechanisms. Techniques such as using neuro-symbolic AI, where symbolic reasoning is combined with neural networks, allow for the creation of models that can explain their reasoning in human-understandable terms. Additionally, methods like neural activity mapping and brain-inspired learning algorithms, such as those leveraging Hebbian learning principles, offer ways to trace AI decision paths back to their origins in the model’s structure.

- **NeuroAI for Safety, Alignment, and Intentional Control:** Bridging neuroscience with AI safety offers promising new frameworks for alignment, interpretability, and robustness. NeuroAI can inform mechanisms for value learning, behavioral priors, and grounded cognition that promote safer AI behavior. Recent work highlights how neuroscience can inspire safer AI by emulating brain architectures, leveraging neural data for interpretability, and scaling cognitive models. Ongoing efforts like [Intentions and AI](https://ai-intentions.org/events/june-2025-workshop/) emphasize the importance of understanding goals, intentions, and internal drives in biological systems—drawing from neuroscience and consciousness research—to differentiate, track, and steer these processes in AI systems. Initiatives like [NeuroAI Safety](https://neuroaisafety.com/) explore how principles such as bounded rationality, attention, and uncertainty minimization can provide robust inductive biases for building AI that is not only intelligent but also predictable, steerable, and aligned with human values.

- **Self-supervised Systems in NeuroAI:** This area of research investigates emerging
paradigms in biological intelligence systems and their integration into artificial systems,
focusing on areas such as predictive coding, active inference, and self-supervised learning.
Integrating self-supervised and unsupervised learning methods inspired by neurobiological processes enables AI systems to learn from unstructured data without explicit labels,
mirroring how biological intelligent systems adapt in real-world environments. This approach enhances the adaptability and intuition of AI technologies,
paving the way for more human-like processing capabilities. The unsupervised learning
mechanisms of the brain or other synthetic biological intelligent systems may be explained
via predictive coding. The theory posits that the brain continuously generates predictions
about incoming sensory data and updates these predictions based on prediction errors.
This framework aligns with active inference, where the brain not only predicts sensory inputs but also acts to minimize surprise, making perception and action two sides of the same
coin. These principles have been exemplified in computational models that emulate
how the brain processes visual information, leading to advancements in computer vision,
autonomous systems, and object recognition.

- **Neuro-inspired reasoning and decision-making:** This topic is an interdisciplinary research area that draws insights from neuroscience, cognitive science, and artificial intelligence to create computational models that emulate the brain's problem-solving capabilities. Here, the aim is to develop systems that can process information, learn from experience, and make decisions in ways that closely resemble human cognition. By incorporating principles such as distributed representations, adaptive learning, and context-sensitive architectures, the aim is to create more flexible, robust, and human-like reasoning systems. Importantly, these models have potential applications across various domains, including robotics, cognitive computing, etc.

- **Cognitive functions in AI:** This research looks to understand the range of mental processes that AI systems emulate from human cognition e.g., language processing, problem-solving, and creativity. For this new methods and benchmarks need to be designed. For example, language processing is evaluated using natural language understanding and generation tests, including translation and summarisation tasks. Reasoning and problem-solving abilities are tested through logic puzzles, mathematical problems, and strategic games. Creativity is a more challenging domain to evaluate, but it's often tested through tasks like generating original stories, artwork, or music. These assessments help researchers gauge the progress of AI systems in replicating human-like cognitive processes and identify new areas for improvement

    

Our workshop aims to explore the intersections among these research areas and provide a platform for researchers to navigate the links between artificial and natural intelligence (see [Call for Papers](https://neuroai-workshop.github.io/call-for-papers/)). Accordingly, we hope to use the workshop as a vehicle for delving deeper into this interdisciplinary landscape; evaluate progress toward a unified (computational) framework for natural intelligence and investigate its potential for artificial intelligence. Through discussions about the current research trajectories in neuroscience and AI, we seek to identify fundamental gaps and challenges, paving the way for novel insights and future directions.


For further information and should you have any inquiries, please contact: [neuroai.neurips2024@gmail.com](mailto:neuroai.neurips2024@gmail.com)



